##LLMs

### Local usage / development
This section is for tips and tricks of running these LLM's locally without the
need for internet connection. Primary idea for me is using them when learning
new things, or local experimentation.
https://replicate.com/blog/run-llama-locally
https://ollama.ai/

This seem to be a good repo for running a LLM locally in a terminal:
https://github.com/adammpkins/llama-terminal-completion 

### Langchain
Here I will possibly add notes about what I learn specific to LangChains. Such
as the difference between chains and agents etc.
